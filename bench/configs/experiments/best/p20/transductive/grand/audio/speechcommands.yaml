run:
  name: best_audio_transductive_grand_speechcommands_p20
  seed: 4
  output_dir: runs/p20/transductive/grand/audio/speechcommands
  fail_fast: true
  log_level: detailed

limits:
  profile: auto

dataset:
  id: speechcommands
  download: true
sampling:
  seed: 4
  plan:
    split:
      kind: holdout
      test_fraction: 0.2
      val_fraction: 0.1
      stratify: true
      shuffle: true
    labeling:
      mode: fraction
      value: 0.20
      strategy: balanced
      min_per_class: 1
    imbalance:
      kind: none
    policy:
      respect_official_test: true
      use_official_graph_masks: true
      allow_override_official: false
preprocess:
  seed: 4
  fit_on: train_labeled
  cache: true
  plan:
    output_key: features.X
    steps:
    - id: labels.encode
    - id: audio.wav2vec2
      params:
        batch_size: 8
    - id: core.pca
      params:
        n_components: 128
    - id: core.to_numpy
method:
  kind: transductive
  id: grand
  device:
    device: "auto"
    dtype: float32
  params:
    hidden_dim: 64
    mlp_dropout: 0.5
    prop_steps: 8
    dropnode: 0.5
    num_samples: 4
    lambda_consistency: 1.0
    lr: 0.01
    weight_decay: 0.0005
    max_epochs: 200
    patience: 50
    add_self_loops: true
evaluation:
  split_for_model_selection: val
  report_splits:
  - val
  - test
  metrics:
  - accuracy
  - macro_f1
graph:
  enabled: true
  seed: 4
  cache: true
  spec:
    scheme: knn
    metric: cosine
    k: 15
    symmetrize: mutual
    weights:
      kind: heat
      sigma: 1.0
    normalize: rw
    self_loops: true
    backend: numpy
    chunk_size: 1024
    feature_field: features.X
