run:
  name: best_audio_transductive_graph_mincuts_speechcommands_p05
  seed: 4
  output_dir: ${MODSSC_OUTPUT_DIR}/p05/transductive/graph_mincuts/audio/speechcommands
  fail_fast: true
  log_level: detailed

limits:
  profile: auto

dataset:
  id: speechcommands
  download: true
  cache_dir: ${MODSSC_DATASET_CACHE_DIR}
  options:
    class_filter:
    - 'yes'
    - 'no'
sampling:
  seed: 4
  plan:
    split:
      kind: holdout
      test_fraction: 0.2
      val_fraction: 0.1
      stratify: true
      shuffle: true
    labeling:
      mode: fraction
      value: 0.05
      strategy: balanced
      min_per_class: 1
    imbalance:
      kind: none
    policy:
      respect_official_test: true
      use_official_graph_masks: true
      allow_override_official: false
preprocess:
  seed: 4
  fit_on: train_labeled
  cache: true
  cache_dir: ${MODSSC_PREPROCESS_CACHE_DIR}
  plan:
    output_key: features.X
    steps:
    - id: labels.encode
    - id: audio.wav2vec2
      params:
        batch_size: 8
    - id: core.pca
      params:
        n_components: 128
    - id: core.to_numpy
method:
  kind: transductive
  id: graph_mincuts
  device:
    device: "auto"
    dtype: float32
  params:
    backend: scipy
    capacity_scale: 1000.0
    min_capacity: 1
evaluation:
  split_for_model_selection: val
  report_splits:
  - val
  - test
  metrics:
  - accuracy
  - macro_f1
graph:
  enabled: true
  seed: 4
  cache: true
  spec:
    scheme: knn
    metric: cosine
    k: 15
    symmetrize: mutual
    weights:
      kind: heat
      sigma: 1.0
    normalize: rw
    self_loops: true
    backend: numpy
    chunk_size: 1024
    feature_field: features.X
