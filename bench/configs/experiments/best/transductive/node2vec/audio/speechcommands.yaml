run:
  name: best_audio_transductive_node2vec_speechcommands
  seed: 4
  output_dir: runs/transductive/node2vec/audio/speechcommands
  fail_fast: true
  log_level: detailed
dataset:
  id: speechcommands
  download: true
sampling:
  seed: 4
  plan:
    split:
      kind: holdout
      test_fraction: 0.2
      val_fraction: 0.1
      stratify: true
      shuffle: true
    labeling:
      mode: fraction
      value: 0.2
      strategy: balanced
      min_per_class: 1
    imbalance:
      kind: none
    policy:
      respect_official_test: true
      use_official_graph_masks: true
      allow_override_official: false
preprocess:
  seed: 4
  fit_on: train_labeled
  cache: true
  plan:
    output_key: features.X
    steps:
    - id: labels.encode
    - id: audio.wav2vec2
      params:
        batch_size: 8
    - id: core.pca
      params:
        n_components: 128
    - id: core.to_numpy
method:
  kind: transductive
  id: node2vec
  device:
    device: "auto"
    dtype: float32
  params:
    embedding_dim: 128
    num_walks: 10
    walk_length: 40
    window_size: 5
    p: 1.0
    q: 1.0
    num_negative: 5
    batch_size: 1024
    embed_epochs: 1
    embed_lr: 0.01
    classifier_lr: 0.1
    classifier_weight_decay: 0.0
    classifier_max_epochs: 200
    classifier_patience: 50
    undirected: true
evaluation:
  split_for_model_selection: val
  report_splits:
  - val
  - test
  metrics:
  - accuracy
  - macro_f1
graph:
  enabled: true
  seed: 4
  cache: true
  spec:
    scheme: knn
    metric: cosine
    k: 15
    symmetrize: mutual
    weights:
      kind: heat
      sigma: 1.0
    normalize: rw
    self_loops: true
    backend: numpy
    chunk_size: 1024
    feature_field: features.X
